# SoftLogic ViDeBERTa: PhÃ¢n tÃ­ch Cáº£m xÃºc NgÃ´n ngá»¯ GenZ Tiáº¿ng Viá»‡t báº±ng Suy luáº­n Logic Má»

Má»™t kiáº¿n trÃºc phÃ¢n tÃ­ch cáº£m xÃºc tiÃªn tiáº¿n dÃ nh cho nghiÃªn cá»©u, Ä‘i sÃ¢u hÆ¡n viá»‡c tinh chá»‰nh (fine-tuning) thÃ´ng thÆ°á»ng báº±ng cÃ¡ch tÃ­ch há»£p suy luáº­n cÆ¡ cháº¿ (mechanistic reasoning), nháº­n diá»‡n xung Ä‘á»™t ngá»¯ nghÄ©a vÃ  thÃ nh kiáº¿n quy náº¡p (inductive bias) â€” táº¥t cáº£ Ä‘á»u cÃ³ thá»ƒ Ä‘áº¡o hÃ m tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i (end-to-end differentiable).

## Cáº£i tiáº¿n Cá»‘t lÃµi

CÃ¡c mÃ´ hÃ¬nh cáº£m xÃºc truyá»n thá»‘ng thÆ°á»ng tháº¥t báº¡i vá»›i ngÃ´n ngá»¯ phi chÃ­nh thá»‘ng cá»§a GenZ vÃ¬ chÃºng:
- Chá»‰ táº­p trung vÃ o cÃ¡c nhÃ£n chiáº¿m Æ°u tháº¿ (vÃ­ dá»¥: "Enjoyment").
- Bá» lá»¡ cÃ¡c mÃ¢u thuáº«n (bá» máº·t tÃ­ch cá»±c + Ã½ Ä‘á»‹nh thá»±c táº¿ tiÃªu cá»±c).
- Dá»±a vÃ o cÃ¡c tá»« khÃ³a bá» máº·t thay vÃ¬ hiá»ƒu Ã½ nghÄ©a sÃ¢u xa.

**SoftLogic ViBERT** (xÃ¢y dá»±ng trÃªn ná»n táº£ng ViDeBERTa) giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» nÃ y thÃ´ng qua:

1. **Token-level TF-IDF Gating**: Sá»­ dá»¥ng trá»ng sá»‘ thá»‘ng kÃª Ä‘á»ƒ loáº¡i bá» nhiá»…u tá»« cÃ¡c token Ã­t quan trá»ng.
2. **Multi-view Representations**: TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« nhiá»u gÃ³c nhÃ¬n: Ngá»¯ nghÄ©a (Semantic), Tá»« vá»±ng (Lexical), vÃ  Ngá»¯ dá»¥ng (Pragmatic).
3. **Differentiable Fuzzy Logic**: Sá»­ dá»¥ng cÃ¡c vá»‹ tá»« má»m (soft predicates) + quy táº¯c má» (fuzzy rules) vá»›i kháº£ nÄƒng há»c Ä‘Æ°á»£c Ä‘á»™ nháº¡y cá»§a phÃ©p toÃ¡n AND.
4. **Conflict Detection**: MÃ´ hÃ¬nh hÃ³a rÃµ rÃ ng sá»± má»‰a mai (sarcasm) vÃ  cÃ¡c mÃ¢u thuáº«n ngá»¯ nghÄ©a.

## Kiáº¿n trÃºc Há»‡ thá»‘ng

```
(ngá»¯ cáº£nh, bÃ¬nh luáº­n)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Token-level TF-IDF Gating     â”‚  â† TÃ­nh toÃ¡n trá»ng sá»‘ thá»‘ng kÃª cho má»—i token
â”‚   s_i = tfidf(token_id_i)       â”‚
â”‚   E'_i = s_i * E_i              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    ViDeBERTa Encoder            â”‚  â† Sá»­ dá»¥ng Fsoft-AIC/videberta-base
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CÃ¡c lá»›p chiáº¿u Multi-view      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚z_sem  â”‚ â”‚z_lex  â”‚ â”‚z_prag â”‚ â”‚
â”‚   â”‚(CLS)  â”‚ â”‚(CNN)  â”‚ â”‚(MLP)  â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MÃ´ Ä‘un Suy luáº­n Logic Má»      â”‚
â”‚                                 â”‚
â”‚   Vá»‹ tá»« (Predicates):           â”‚
â”‚   P_pos_sem, P_neg_sem,         â”‚
â”‚   P_pos_lex, P_neg_lex,         â”‚
â”‚   P_high_int âˆˆ (0,1)            â”‚
â”‚                                 â”‚
â”‚   Quy táº¯c (Rules):              â”‚
â”‚   r1 = AND(P_pos_lex, P_neg_sem)â”‚  â† Má»‰a mai
â”‚   r2 = AND(P_neg_lex, P_neg_sem)â”‚  â† TiÃªu cá»±c máº¡nh
â”‚   r3 = AND(P_pos_sem, NOT(P_high_int))
â”‚   r4 = AND(P_high_int, P_neg_sem)
â”‚   r5 = |P_pos_lex - P_pos_sem|  â”‚  â† Sá»± khÃ´ng nháº¥t quÃ¡n
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MLP Suy luáº­n Cáº£m xÃºc          â”‚
â”‚   [z_sem, z_lex, z_prag, r1-r5] â”‚
â”‚            â†“                    â”‚
â”‚   PhÃ¢n loáº¡i Äa nhÃ£n (Multi-label)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## CÃ i Ä‘áº·t

```bash
# Clone repository
git clone <repository>
cd softlogic_vibert

# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
pip install -r requirements.txt
```

### YÃªu cáº§u há»‡ thá»‘ng
- Python 3.8+
- PyTorch 1.10+
- Transformers 4.20+
- (TÃ¹y chá»n) CUDA Ä‘á»ƒ tÄƒng tá»‘c báº±ng GPU

## HÆ°á»›ng dáº«n nhanh

### Huáº¥n luyá»‡n (Training)

```bash
# Huáº¥n luyá»‡n vá»›i dá»¯ liá»‡u JSON/JSONL cá»¥c bá»™
python -m softlogic_vibert.train \
    --data-path output_data.json \
    --output-dir softlogic_outputs \
    --epochs 10 \
    --batch-size 16

# Huáº¥n luyá»‡n vá»›i táº­p dá»¯ liá»‡u tá»« HuggingFace
python -m softlogic_vibert.train \
    --hf-dataset tridm/UIT-VSMEC \
    --hf-split train \
    --output-dir softlogic_outputs
```

### Dá»± Ä‘oÃ¡n (Inference)

```bash
# Dá»± Ä‘oÃ¡n má»™t cÃ¢u kÃ¨m phÃ¢n tÃ­ch chi tiáº¿t
python -m softlogic_vibert.inference \
    --ckpt softlogic_outputs/softlogic_vibert_state.pt \
    --comment "em yÃªu anh quÃ¡ Ä‘i ğŸ˜ğŸ˜ğŸ˜" \
    --verbose

# Xuáº¥t káº¿t quáº£ Ä‘á»‹nh dáº¡ng JSON
python -m softlogic_vibert.inference \
    --ckpt softlogic_outputs/softlogic_vibert_state.pt \
    --comment "ngon tháº­t Ä‘áº¥y ğŸ™„" \
    --json
```

### Sá»­ dá»¥ng qua Python API:

```python
from softlogic_vibert import SentimentPredictor

path = "outputs/softlogic_vibert_state.pt"
device = "cpu"  # hoáº·c "cuda"

model = SentimentPredictor.load(path, device=device)

comment = "ngon tháº­t Ä‘áº¥y ğŸ™„"
context = "ÄÃ¢y lÃ  nhÃ  hÃ ng má»›i má»Ÿ"

# LÆ°u Ã½: predict(comment, context). Sá»­ dá»¥ng tá»« khÃ³a Ä‘á»ƒ trÃ¡nh nháº§m láº«n thá»© tá»± Ä‘á»‘i sá»‘.
pred = model.predict(comment=comment, context=context)
print("NhÃ£n dá»± Ä‘oÃ¡n lÃ :", pred)
```

### NghiÃªn cá»©u BÃ³c tÃ¡ch (Ablation Studies)

```bash
# Cháº¡y cÃ¡c thá»­ nghiá»‡m cá»‘t lÃµi
python -m softlogic_vibert.ablation run \
    --data-path output_data.json \
    --experiments core \
    --epochs 5

# Cháº¡y táº¥t cáº£ cÃ¡c thá»­ nghiá»‡m
python -m softlogic_vibert.ablation run \
    --data-path output_data.json \
    --experiments all

# So sÃ¡nh káº¿t quáº£
python -m softlogic_vibert.ablation compare \
    --study-dir ablation_results/ablation_study_YYYYMMDD_HHMMSS
```

## Cáº¥u hÃ¬nh BÃ³c tÃ¡ch

| Cáº¥u hÃ¬nh | Masking | Multi-view | Logic | MÃ´ táº£ |
|--------------|---------|------------|-------|-------------|
| `vibert_only` | KhÃ´ng | KhÃ´ng | KhÃ´ng | Chá»‰ sá»­ dá»¥ng mÃ´ hÃ¬nh gá»‘c (ViDeBERTa) |
| `mask_only` | CÃ³ | KhÃ´ng | KhÃ´ng | Backbone + TF-IDF gating |
| `multiview_no_logic` | CÃ³ | CÃ³ | KhÃ´ng | Multi-view nhÆ°ng khÃ´ng cÃ³ suy luáº­n logic |
| `full_model` | CÃ³ | CÃ³ | CÃ³ | Kiáº¿n trÃºc Ä‘áº§y Ä‘á»§ |
| `drop_r1` - `drop_r5` | CÃ³ | CÃ³ | CÃ³* | Loáº¡i bá» tá»«ng quy táº¯c riÃªng láº» |

CÃ¡c cá» dÃ²ng lá»‡nh:
```bash
# Baseline chá»‰ backbone
--no-mask --no-multiview --no-logic

# Chá»‰ masking
--use-mask --no-multiview --no-logic

# Multi-view (khÃ´ng logic)
--use-mask --use-multiview --no-logic

# MÃ´ hÃ¬nh Ä‘áº§y Ä‘á»§
--use-mask --use-multiview --use-logic

# Loáº¡i bá» cÃ¡c quy táº¯c cá»¥ thá»ƒ
--drop-rules r1,r5
```

## Äá»‹nh dáº¡ng Dá»¯ liá»‡u

Äá»‹nh dáº¡ng JSON/JSONL mong muá»‘n:

```json
{
    "comment": "ngon tháº­t Ä‘áº¥y ğŸ™„",
    "context": "ÄÃ¢y lÃ  nhÃ  hÃ ng má»›i má»Ÿ",
    "labels": ["Disgust", "Sarcasm"]
}
```

- `comment`: Báº¯t buá»™c. VÄƒn báº£n ngÆ°á»i dÃ¹ng (tá»« lÃ³ng GenZ, emoji, ngÃ´n ngá»¯ phi chÃ­nh thá»©c).
- `context`: TÃ¹y chá»n. ThÃ´ng tin ngá»¯ cáº£nh bá»• sung.
- `labels`: Danh sÃ¡ch Ä‘a nhÃ£n (vÃ­ dá»¥: Enjoyment, Anger, Disgust, Surprise, Fear, Sadness, Other).

## Kháº£ nÄƒng Giáº£i thÃ­ch (Interpretability)

### PhÃ¢n tÃ­ch chi tiáº¿t qua API

```python
from softlogic_vibert import create_interpreter

# Táº¡o trÃ¬nh giáº£i thÃ­ch tá»« checkpoint
interpreter = create_interpreter("outputs/softlogic_vibert_state.pt")

# PhÃ¢n tÃ­ch má»™t máº«u dá»¯ liá»‡u
result = interpreter.analyze(
    comment="ngon tháº­t Ä‘áº¥y ğŸ™„",
    context="NhÃ  hÃ ng nÃ y review 5 sao"
)

# Láº¥y phÃ¢n tÃ­ch chi tiáº¿t
print(result.predicted_labels)       # ['Disgust']
print(result.rule_activations)       # KÃ­ch hoáº¡t luáº­t suy luáº­n: {'r1': 0.82, 'r2': 0.21, ...}
print(result.important_tokens)       # CÃ¡c token quan trá»ng: ['ngon', 'tháº­t', 'Ä‘áº¥y']
print(result.reasoning_summary)      # TÃ³m táº¯t suy luáº­n: {'sarcasm_likely': True, ...}

# Giáº£i thÃ­ch báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn
explanation = interpreter.explain_prediction(
    comment="ngon tháº­t Ä‘áº¥y ğŸ™„"
)
print(explanation)
```

### Truy cáº­p Token Masks

```python
from softlogic_vibert import load_model, predict_single

model, tokenizer, ckpt = load_model("outputs/softlogic_vibert_state.pt")

result = predict_single(
    model, tokenizer,
    comment="em yÃªu anh quÃ¡ Ä‘i",
    return_details=True
)

# Má»©c Ä‘á»™ quan trá»ng cá»§a token
for token_info in result["token_masks"]:
    print(f"{token_info['token']}: {token_info['mask_value']:.3f}")

# KÃ­ch hoáº¡t quy táº¯c
for rule, value in result["rule_activations"].items():
    print(f"{rule}: {value:.3f}")
```

## MÃ´ Ä‘un Logic Má» (Soft Logic Module)

### CÃ¡c phÃ©p toÃ¡n cÃ³ thá»ƒ Ä‘áº¡o hÃ m

```python
# Fuzzy AND (tÃ­ch t-norm tham sá»‘ hÃ³a)
# p lÃ  má»™t scalar há»c Ä‘Æ°á»£c (Ä‘Æ°á»£c káº¹p trong code)
AND(a, b) = (a * b) ** p

# Fuzzy OR (tá»•ng xÃ¡c suáº¥t)
OR(a, b) = a + b - a*b

# Fuzzy NOT (pháº§n bÃ¹)
NOT(a) = 1 - a

# Fuzzy implication (toÃ¡n tá»­ Reichenbach)
IMPLIES(a, b) = 1 - a + a*b
```

### Quy táº¯c Suy luáº­n

| Quy táº¯c | CÃ´ng thá»©c | Ã nghÄ©a giáº£i thÃ­ch |
|------|---------|----------------|
| r1 | `AND(P_pos_lex, P_neg_sem)` | Má»‰a mai / Contradiction (Bá» máº·t tÃ­ch cá»±c, Ã½ nghÄ©a tiÃªu cá»±c) |
| r2 | `AND(P_neg_lex, P_neg_sem)` | TiÃªu cá»±c máº¡nh (Cáº£ tá»« vá»±ng vÃ  ngá»¯ nghÄ©a Ä‘á»u tiÃªu cá»±c) |
| r3 | `AND(P_pos_sem, NOT(P_high_int))` | TÃ­ch cá»±c nháº¹ (Ngá»¯ nghÄ©a tÃ­ch cá»±c nhÆ°ng cÆ°á»ng Ä‘á»™ khÃ´ng cao) |
| r4 | `AND(P_high_int, P_neg_sem)` | TiÃªu cá»±c dá»¯ dá»™i (CÆ°á»ng Ä‘á»™ cao + ngá»¯ nghÄ©a tiÃªu cá»±c) |
| r5 | `\|P_pos_lex - P_pos_sem\|` | Sá»± khÃ´ng nháº¥t quÃ¡n (MÃ¢u thuáº«n giá»¯a cáº£m xÃºc bá» máº·t vÃ  ngá»¯ nghÄ©a) |

## Máº¹o Huáº¥n luyá»‡n

### Xá»­ lÃ½ Máº¥t cÃ¢n báº±ng Lá»›p

```bash
# Sá»­ dá»¥ng focal loss cho dá»¯ liá»‡u máº¥t cÃ¢n báº±ng
python -m softlogic_vibert.train \
    --loss-type focal \
    --focal-gamma 2.0 \
    ...

# Sá»­ dá»¥ng asymmetric loss (khuyáº¿n nghá»‹ cho Ä‘a nhÃ£n)
python -m softlogic_vibert.train \
    --loss-type asymmetric \
    ...
```

### Äiá»u chá»‰nh Tá»‘c Ä‘á»™ Há»c

```bash
# Tá»‘c Ä‘á»™ há»c khÃ¡c nhau cho encoder vÃ  cÃ¡c head
python -m softlogic_vibert.train \
    --lr 2e-5 \
    --encoder-lr 2e-5 \
    --head-lr 5e-4 \
    ...
```

### Huáº¥n luyá»‡n vá»›i Äá»™ chÃ­nh xÃ¡c Há»—n há»£p

```bash
# Báº­t FP16 Ä‘á»ƒ huáº¥n luyá»‡n nhanh hÆ¡n (yÃªu cáº§u CUDA)
python -m softlogic_vibert.train \
    --fp16 \
    ...
```

## Cáº¥u trÃºc Dá»± Ã¡n

```
softlogic_vibert/
â”œâ”€â”€ __init__.py          # Khai bÃ¡o package
â”œâ”€â”€ config.py            # CÃ¡c dataclass cáº¥u hÃ¬nh
â”œâ”€â”€ model.py             # MÃ´ hÃ¬nh SoftLogicViBERT cá»‘t lÃµi
â”œâ”€â”€ train.py             # Ká»‹ch báº£n huáº¥n luyá»‡n
â”œâ”€â”€ inference.py         # Ká»‹ch báº£n dá»± Ä‘oÃ¡n
â”œâ”€â”€ losses.py            # CÃ¡c hÃ m loss tÃ¹y chá»‰nh
â”œâ”€â”€ metrics.py           # CÃ¡c Ä‘á»™ Ä‘o Ä‘Ã¡nh giÃ¡
â”œâ”€â”€ data.py              # CÃ¡c tiá»‡n Ã­ch táº£i dá»¯ liá»‡u
â”œâ”€â”€ utils.py             # CÃ¡c hÃ m trá»£ giÃºp
â”œâ”€â”€ ablation.py          # TrÃ¬nh cháº¡y nghiÃªn cá»©u bÃ³c tÃ¡ch
â”œâ”€â”€ interpretability.py  # CÃ´ng cá»¥ phÃ¢n tÃ­ch mÃ´ hÃ¬nh
â””â”€â”€ README.md            # File nÃ y
```

## CÃ¡c Checkpoint Ä‘Ã£ LÆ°u

QuÃ¡ trÃ¬nh huáº¥n luyá»‡n táº¡o ra:
- `softlogic_vibert_state.pt`: State dict (nháº¹, khuyáº¿n nghá»‹)
- `softlogic_vibert_full.pt`: Äá»‘i tÆ°á»£ng mÃ´ hÃ¬nh Ä‘áº§y Ä‘á»§
- `train_summary.json`: TÃ³m táº¯t cÃ¡c Ä‘á»™ Ä‘o huáº¥n luyá»‡n
- `training_history.json`: CÃ¡c Ä‘á»™ Ä‘o theo tá»«ng epoch
- `config.json`: Cáº¥u hÃ¬nh thá»­ nghiá»‡m

## Sá»­ dá»¥ng NÃ¢ng cao

### VÃ²ng láº·p Huáº¥n luyá»‡n TÃ¹y chá»‰nh

```python
from softlogic_vibert import (
    SoftLogicViBERT, ModelConfig, SoftLogicLoss,
    load_and_prepare_data, prepare_dataloaders
)
from transformers import AutoTokenizer
import torch

# Cáº¥u hÃ¬nh
config = ModelConfig(
    model_name="Fsoft-AIC/videberta-base",
    use_mask=True,
    use_multiview=True,
    use_logic=True,
)

# Táº£i dá»¯ liá»‡u
tokenizer = AutoTokenizer.from_pretrained(config.model_name)
train_rows, val_rows, label_map, label_list = load_and_prepare_data("data.json")
train_loader, val_loader = prepare_dataloaders(
    train_rows, val_rows, tokenizer, label_map
)

# Create model
config.num_labels = len(label_map)
model = SoftLogicViBERT(config).cuda()

# Custom training...
```

### Extending the Logic Module

```python
class ExtendedLogicModule(SoftLogicModule):
    def __init__(self, proj_size):
        super().__init__(proj_size)
        # Add custom predicates
        self.pred_custom = SoftPredicate(proj_size)
    
    def forward(self, z_sem, z_lex, z_prag):
        base_rules, base_details = super().forward(z_sem, z_lex, z_prag)
        
        # Add custom rule
        p_custom = self.pred_custom(z_sem)
        r_custom = self.AND(p_custom, base_details["p_high_int"])
        
        # Extend outputs...
        return extended_rules, extended_details
```

## Citation

If you use this code in your research, please cite:

```bibtex
@software{softlogic_vibert,
    title = {SoftLogic ViDeBERTa (SoftLogic ViBERT): Soft-Logic Reasoning for Vietnamese GenZ Sentiment},
  year = {2024},
  description = {A novel sentiment analysis architecture with differentiable fuzzy logic}
}
```

## License

This project is released for research purposes.

## Acknowledgments

- ViDeBERTa backbone (Fsoft-AIC/videberta-base)
- HuggingFace Transformers
- PyTorch team
